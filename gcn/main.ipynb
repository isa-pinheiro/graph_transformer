{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDf66qdxVcaF"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.datasets import ZINC\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voUgfGGwVdo7",
        "outputId": "22b46421-1821-46e0-bae1-e2e7fee8c738"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waRfXZpeVi2L",
        "outputId": "cac9a48e-4869-44c7-9ef1-2809f9ccf662"
      },
      "outputs": [],
      "source": [
        "train_dataset = ZINC(root='data/ZINC', subset=True, split='train')\n",
        "val_dataset = ZINC(root='data/ZINC', subset=True, split='val')\n",
        "test_dataset = ZINC(root='data/ZINC', subset=True, split='test')\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "print(f\"Tamanho dos datasets:\")\n",
        "print(f\"Treino: {len(train_dataset)} amostras\")\n",
        "print(f\"Validação: {len(val_dataset)} amostras\")\n",
        "print(f\"Teste: {len(test_dataset)} amostras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dR2xZDmVlhW"
      },
      "outputs": [],
      "source": [
        "class GCNGraph(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=10):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "\n",
        "        self.convs.append(GCNConv(in_channels, hidden_channels))\n",
        "\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.convs.append(GCNConv(hidden_channels, hidden_channels))\n",
        "\n",
        "        self.convs.append(GCNConv(hidden_channels, hidden_channels))\n",
        "\n",
        "        self.lin = torch.nn.Linear(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        for conv in self.convs:\n",
        "            x = conv(x, edge_index)\n",
        "            x = F.relu(x)\n",
        "\n",
        "        x = global_mean_pool(x, batch)\n",
        "\n",
        "        return self.lin(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w48Ad449VnCQ"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, loader, optimizer, loss_fn, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for batch in loader:\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        out = model(batch.x.float(), batch.edge_index, batch.batch)\n",
        "        out = out.view(-1)                \n",
        "        target = batch.y.view(-1).float() \n",
        "\n",
        "        loss = loss_fn(out, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bosEhxc6WLka"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def eval_epoch(model, loader, loss_fn, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for batch in loader:\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        out = model(batch.x.float(), batch.edge_index, batch.batch)\n",
        "        out = out.view(-1)\n",
        "        target = batch.y.view(-1).float()\n",
        "\n",
        "        loss = loss_fn(out, target)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpGkguDKVrY5"
      },
      "outputs": [],
      "source": [
        "def train_gcn_regression(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    test_loader,\n",
        "    device,\n",
        "    epochs=50,\n",
        "    lr=1e-3\n",
        "):\n",
        "    model = model.to(device)\n",
        "\n",
        "    loss_fn = torch.nn.L1Loss()  # MAE\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    history = {\n",
        "        \"epoch\": [],\n",
        "        \"train_loss\": [],\n",
        "        \"val_mae\": []\n",
        "    }\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        train_loss = train_epoch(\n",
        "            model, train_loader, optimizer, loss_fn, device\n",
        "        )\n",
        "        val_mae = eval_epoch(\n",
        "            model, val_loader, loss_fn, device\n",
        "        )\n",
        "\n",
        "        history[\"epoch\"].append(epoch + 1)\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "        history[\"val_mae\"].append(val_mae)\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch+1:03d} | \"\n",
        "            f\"Train Loss: {train_loss:.4f} | \"\n",
        "            f\"Val MAE: {val_mae:.4f}\"\n",
        "        )\n",
        "\n",
        "    test_mae = eval_epoch(model, test_loader, loss_fn, device)\n",
        "    print(f\"Test MAE: {test_mae:.4f}\")\n",
        "\n",
        "    history[\"test_mae\"] = [None] * (epochs - 1) + [test_mae]\n",
        "\n",
        "    return history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39QwGg6aVuKJ",
        "outputId": "f954de89-e303-4f4c-d59c-3e3aa4d30d0a"
      },
      "outputs": [],
      "source": [
        "for seed in [42, 7, 5, 9]:\n",
        "  set_seed(seed)\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  model = GCNGraph(\n",
        "    in_channels=train_dataset.num_features,\n",
        "    hidden_channels=16,\n",
        "    out_channels=1\n",
        "  )\n",
        "\n",
        "  history = train_gcn_regression(\n",
        "      model=model,\n",
        "      train_loader=train_loader,\n",
        "      val_loader=val_loader,\n",
        "      test_loader=test_loader,\n",
        "      device=device,\n",
        "      epochs=50,\n",
        "      lr=1e-3\n",
        "  )\n",
        "\n",
        "  df = pd.DataFrame(history)\n",
        "  df.to_csv(f\"training_metrics.csv_{seed}\", index=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
